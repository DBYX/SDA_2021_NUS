{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "peripheral-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import numpy as np\n",
    "import logging\n",
    "import imageio\n",
    "import moviepy.editor as mp\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from scipy.cluster.hierarchy import ClusterWarning\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", ClusterWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "\n",
    "formatter = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(filename='cluster_analysis.log', filemode='w', level=logging.INFO, format=formatter)\n",
    "\n",
    "sectors = ['basic_industries', 'capital_goods', 'consumer_durables', 'consumer_nondurables', 'consumer_services', \\\n",
    "            'energy', 'finance', 'health_care','miscellaneous','public_utilities','technology','transportation']\n",
    "\n",
    "def symbol_to_path(symbol):\n",
    "    # download data from https://drive.google.com/file/d/1Uy0VmrkbKUAskGKAAQo45F8unrphAF14/view?usp=sharing\n",
    "    # and save to downloaded_data/data/ folder\n",
    "    if os.path.exists('downloaded_data/data/'):\n",
    "        return \"downloaded_data/data/{}.csv\".format(str(symbol))\n",
    "    else:\n",
    "        logging.error('please make sure path \\'downloaded_data/data/\\' is present under current working directory!')\n",
    "        exit(1)\n",
    "\n",
    "def get_symbols_from_file(file_path):\n",
    "    symbols = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for s in lines:\n",
    "            s = s.strip()\n",
    "            if os.path.exists(symbol_to_path(s)):\n",
    "                symbols.append(s)\n",
    "            else:\n",
    "                logging.info('data file for symbol {} does not exist!'.format(s))\n",
    "    return symbols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decent-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbols):\n",
    "    ''' \n",
    "    function to return dataframe of Adj Close price for symbols from downloaded_data set\n",
    "    '''\n",
    "    first = True\n",
    "    for symbol in symbols:\n",
    "        if first:\n",
    "            # if first = True, construct df\n",
    "            df = pd.read_csv(symbol_to_path(symbol), parse_dates=True, usecols=['Date', 'Adj Close'], na_values=['nan'])\n",
    "            df.rename(columns={'Adj Close': symbol}, inplace=True)\n",
    "            first = False\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                df_temp = pd.read_csv(symbol_to_path(symbol),\n",
    "                                    parse_dates=True, usecols=['Date', 'Adj Close'], na_values=['nan'])\n",
    "\n",
    "                df_temp = df_temp.rename(columns={'Adj Close': symbol})\n",
    "                df = pd.merge(left=df, right=df_temp, how='outer', left_on='Date', right_on='Date')\n",
    "            except Exception as e: \n",
    "                logging.error('error received when trying to append df for symbol {}: {}'.format(symbol, e))\n",
    "\n",
    "    # df.set_index('Date')\n",
    "    # df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "geographic-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_index(sym_file, index_file_name):\n",
    "    if not os.path.exists(sym_file):\n",
    "        logging.error('Error when constructing index: not able to find file: {}'.format(sym_file))\n",
    "        return \n",
    "\n",
    "    components = get_symbols_from_file(sym_file)\n",
    "    data = get_data(components)\n",
    "    data.set_index('Date', inplace=True)\n",
    "    data.sort_index(inplace=True)\n",
    "    df = pd.DataFrame(index=data.index)\n",
    "    # use simple average of price here for index construction\n",
    "    df['Adj Close'] = data.mean(axis=1)\n",
    "    df.to_csv(index_file_name) \n",
    "\n",
    "def sector_index():\n",
    "    f = open('sectors/index_names.csv', 'w')\n",
    "    for s in sectors:\n",
    "        sym_file = 'sectors/{}_sym.csv'.format(s)\n",
    "        output = 'downloaded_data/data/{}_index.csv'.format(s)\n",
    "        try: \n",
    "            logging.info('Constructing index for sector: {}'.format(s))\n",
    "            construct_index(sym_file, output)\n",
    "            f.write('{}_index\\n'.format(s))\n",
    "        except Exception as e:\n",
    "            logging.error('Error when constructing sector index for sector: {}, {}'.format(s,e))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def industry_index():\n",
    "    industries = []\n",
    "    with open('industries/industry_list.csv', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        industries.extend([line.strip() for line in lines])\n",
    "\n",
    "    f = open('industries/industry_index_names.csv', 'w')\n",
    "    for i in industries:\n",
    "        sym_file = 'industries/{}_sym.csv'.format(i)\n",
    "        output = 'downloaded_data/data/{}_ind_index.csv'.format(i)\n",
    "        try: \n",
    "            logging.info('Constructing index for industry: {}'.format(i))\n",
    "            construct_index(sym_file, output)\n",
    "            logging.info('Constructed successfully, place file at {}'.format(output))\n",
    "            f.write('{}_ind_index\\n'.format(i))\n",
    "        except Exception as e:\n",
    "            logging.error('Error when constructing industry index for industry: {}, {}'.format(i,e))\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floral-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlDist(corr):\n",
    "    dist = ((1-corr)/2.)**.5\n",
    "    return dist\n",
    "\n",
    "def getQuasiDiag(link):\n",
    "    link = link.astype(int)\n",
    "    sortIx = pd.Series([link[-1,0],link[-1,1]])\n",
    "    numItems = link[-1,3]\n",
    "    while sortIx.max()>=numItems:\n",
    "        sortIx.index = range(0,sortIx.shape[0]*2,2)\n",
    "        df0 = sortIx[sortIx>=numItems]\n",
    "        i=df0.index\n",
    "        j=df0.values-numItems\n",
    "        sortIx[i] = link[j,0]\n",
    "        df0 = pd.Series(link[j,1],index=i+1)\n",
    "        sortIx = sortIx.append(df0)\n",
    "        sortIx = sortIx.sort_index()\n",
    "        sortIx.index = range(sortIx.shape[0])\n",
    "    return sortIx.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conscious-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_plot(data, start, end, figname, cluster=True):\n",
    "    data_tmp = data.loc[start:end, :]\n",
    "    corr = data_tmp.pct_change().corr()\n",
    "    plt.figure(figsize = (20,20))\n",
    "\n",
    "    if cluster:\n",
    "        dist = correlDist(corr)\n",
    "        dist_n = dist.fillna(0)\n",
    "        try:\n",
    "            link = sch.linkage(dist_n, 'single')\n",
    "            sortIx = getQuasiDiag(link)\n",
    "        except Exception as e:\n",
    "            logging.error('received error when trying to get sortIx: {}'.format(e))\n",
    "\n",
    "        sortIx = corr.index[sortIx].tolist()\n",
    "        df0 = corr.loc[sortIx, sortIx]\n",
    "\n",
    "        sns_plot = sns.heatmap(df0, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\n",
    "        fig = sns_plot.get_figure()\n",
    "        fig.savefig(figname)\n",
    "    else:\n",
    "        sns_plot = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\n",
    "        fig = sns_plot.get_figure()\n",
    "        fig.savefig(figname)\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "modern-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(sym_file, category):\n",
    "    start_dates = ['2011-03-16', \n",
    "                   '2012-03-16', \n",
    "                   '2013-03-16', \n",
    "                   '2014-03-16', \n",
    "                   '2015-03-16', \n",
    "                   '2016-03-16',\n",
    "                   '2017-03-16', \n",
    "                   '2018-03-16',\n",
    "                   '2019-03-16',\n",
    "                   '2020-03-16']\n",
    "\n",
    "    end_dates = ['2012-03-16', \n",
    "                 '2013-03-16', \n",
    "                 '2014-03-16', \n",
    "                 '2015-03-16', \n",
    "                 '2016-03-16',\n",
    "                 '2017-03-16', \n",
    "                 '2018-03-16',\n",
    "                 '2019-03-16',\n",
    "                 '2020-03-16', \n",
    "                 '2021-03-16']\n",
    "\n",
    "    assert len(start_dates) == len(end_dates), 'length of start dates and end dates must be same'\n",
    "    if not os.path.exists(sym_file):\n",
    "        logging.error('{} does not exist, please make sure the file path is valid!'.format(sym_file))\n",
    "        return \n",
    "\n",
    "    symbols = get_symbols_from_file(sym_file)\n",
    "    data = get_data(symbols)\n",
    "    data.set_index('Date', inplace=True)\n",
    "    data.sort_index(inplace=True)\n",
    "    # data.to_csv('data_{}.csv'.format(category))\n",
    "\n",
    "    figure_path = 'figures/{}'.format(category)\n",
    "\n",
    "    if not (os.path.exists(figure_path) and os.path.isdir(figure_path)):\n",
    "        os.makedirs(figure_path)\n",
    "\n",
    "    logging.info('{}: plotting corr graph for 10 years interval'.format(category))\n",
    "    cluster_plot(data, '2011-03-16', '2021-03-15', '{}/{}_corr_10y.png'.format(figure_path, category), False)\n",
    "    logging.info('{}: plotting clustered corr graph for 10 years interval'.format(category))\n",
    "    cluster_plot(data, '2011-03-16', '2021-03-15', '{}/{}_corr_cluster_10y.png'.format(figure_path, category), True)\n",
    "\n",
    "    for (i,(s,e)) in enumerate(zip(start_dates, end_dates)):\n",
    "        logging.info('clustering plotting for {} during time period: {} to {}'.format(category, s, e))\n",
    "        cluster_plot(data, start_dates[i], end_dates[i], '{}/{}_corr_time_{}.png'.format(figure_path, category, i))\n",
    "    logging.info('{}: plotted corr clustering for the time intervals'.format(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "tamil-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(sym_file, category, start, end, interval=30, window=360, cluster=True):\n",
    "    start_date = datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end, '%Y-%m-%d')\n",
    "    if not os.path.exists(sym_file):\n",
    "        logging.error('{} does not exist, please make sure the file path is valid!'.format(sym_file))\n",
    "        return \n",
    "\n",
    "    symbols = get_symbols_from_file(sym_file)\n",
    "    data = get_data(symbols)\n",
    "    data.set_index('Date', inplace=True)\n",
    "    data.sort_index(inplace=True)\n",
    "    animation_path = 'animations/{}'.format(category)\n",
    "\n",
    "    if not (os.path.exists(animation_path) and os.path.isdir(animation_path)):\n",
    "        os.makedirs(animation_path)\n",
    "\n",
    "    logging.info('{}: plotting corr animation for window {} and interval {}, start: {}, end: {}'.format(category, window, interval, start, end))\n",
    "    images = []\n",
    "\n",
    "    i = 0\n",
    "    while start_date + timedelta(days=window) < end_date: \n",
    "        s = start_date.strftime('%Y-%m-%d')\n",
    "        e = (start_date + timedelta(days=window)).strftime('%Y-%m-%d')\n",
    "        data_tmp = data.loc[s:e, :]\n",
    "        corr = data_tmp.pct_change().corr()\n",
    "\n",
    "        plt.figure(figsize=(20,20))\n",
    "        if cluster:\n",
    "            dist = correlDist(corr)\n",
    "            dist_n = dist.fillna(0)\n",
    "            try:\n",
    "                link = sch.linkage(dist_n, 'single')\n",
    "                sortIx = getQuasiDiag(link)\n",
    "            except Exception as e:\n",
    "                logging.error('received error when trying to get sortIx: {}'.format(e))\n",
    "\n",
    "            sortIx = corr.index[sortIx].tolist()\n",
    "            df0 = corr.loc[sortIx, sortIx]\n",
    "\n",
    "            sns_plot=sns.heatmap(df0, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\n",
    "            fig = sns_plot.get_figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.set_title('Corr {} - {}'.format(s, e))\n",
    "            figname = os.path.join(animation_path, 'animate_{}.png'.format(i))\n",
    "            fig.savefig(figname)\n",
    "            images.append(imageio.imread(figname))\n",
    "            plt.close()\n",
    "\n",
    "        else:\n",
    "            sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\n",
    "            fig = sns_plot.get_figure()\n",
    "            figname = os.path.join(animation_path, 'animate_{}.png'.format(i))\n",
    "            fig.savefig(figname)\n",
    "            images.append(imageio.imread(figname))\n",
    "            plt.close()\n",
    "\n",
    "        start_date += timedelta(days=interval)\n",
    "        i += 1\n",
    "\n",
    "    imageio.mimsave(os.path.join(animation_path,'{}.gif'.format(category)), images, fps=1)\n",
    "    clip = mp.VideoFileClip(os.path.join(animation_path,'{}.gif'.format(category)))\n",
    "    clip.write_videofile(os.path.join(animation_path,'{}.mp4'.format(category)))\n",
    "    logging.info('{}: corr animation saved at {}'.format(category, animation_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "proved-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # run('sp500_symbol.csv', 'SP500')\n",
    "    logging.info('Starting the process...')\n",
    "\n",
    "    logging.info('{}: process for {} symbols'.format('SP500', 'SP500'))\n",
    "    run('sectors/sp500_symbol.csv', 'SP500')\n",
    "\n",
    "    for s in sectors:\n",
    "        logging.info('{}: process for {} symbols'.format(s, s))\n",
    "        try:\n",
    "            run('sectors/{}_sym.csv'.format(s), s)\n",
    "        except Exception as e:\n",
    "            logging.error('Error when trying to process for sector: {}, {}'.format(s, e))\n",
    "\n",
    "    if not os.path.exists('sectors/index_names.csv'):\n",
    "        logging.info('Constructing sector index...')\n",
    "        sector_index()\n",
    "        logging.info('Sector index constructed!')\n",
    "    \n",
    "    logging.info('Plotting for sector index corr...')\n",
    "    try:\n",
    "        run('sectors/index_names.csv', 'sector')\n",
    "    except Exception as e:\n",
    "        logging.error('Error when trying to process sector index corr: {}'.format(e))\n",
    "\n",
    "    if not os.path.exists('industries/industry_index_names.csv'):\n",
    "        logging.info('Constructing industry index...')\n",
    "        industry_index()\n",
    "        logging.info('Industry index constructed!')\n",
    "    \n",
    "    logging.info('Plotting for industry index corr...')\n",
    "    try:\n",
    "        run('industries/industry_index_names.csv', 'industry')\n",
    "    except Exception as e:\n",
    "        logging.error('Error when trying to process industry index corr: {}'.format(e))\n",
    "\n",
    "    logging.info('End of the process. BYE!')\n",
    "    print('Process Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "developing-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  57%|█████▋    | 4/7 [00:00<00:00, 37.90it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video animations/SP500/SP500.mp4.\n",
      "Moviepy - Writing video animations/SP500/SP500.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready animations/SP500/SP500.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "animate('sectors/sp500_symbol.csv', 'SP500', '2017-03-15', '2021-03-15', 180)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
